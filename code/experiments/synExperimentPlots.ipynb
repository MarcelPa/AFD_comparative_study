{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19580bd7-7191-4233-a99b-5b39140af600",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SYN plot\n",
    "\n",
    "In this notebook, we generate the data to plot the figures for SYN.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Set the execution path for Python and set the results path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2179a4d-bcaf-4206-822d-1f50c90ec184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# for Jupyter notebooks: add the path of 'code' to allow importing module\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "results_path = \"../../results\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75ffbcd-e53e-4fb0-995e-961bfd348b22",
   "metadata": {},
   "source": [
    "## Define generic method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dd931c-103b-49e3-9b6d-284d6bf7fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "measure_order = [\n",
    "    \"rho\", 'g2', 'g3', 'g3_prime', 'fraction_of_information', 'reliable_fraction_of_information_prime', 'smoothed_fraction_of_information', 'g1', 'g1_prime', 'pdep', 'tau', 'mu_prime'\n",
    "]\n",
    "\n",
    "def make_SYN_err_data(\n",
    "    df: pd.DataFrame,\n",
    "    x: str,\n",
    "    bins: int = 21,\n",
    "    min_val: float = 0.0,\n",
    "    max_val: float = 1.0,\n",
    ") -> Dict[Tuple[str, bool], pd.DataFrame]:\n",
    "    _df = df.copy()\n",
    "    _bins = np.linspace(min_val, max_val, num=bins)\n",
    "    _df[\"group\"] = pd.cut(_df[x], bins=_bins, include_lowest=True, labels=_bins[:-1])\n",
    "    dataset_dfs = {}\n",
    "    for measure in measure_order:\n",
    "        _local_df = pd.DataFrame(index=_bins)\n",
    "        for fd in (True, False):\n",
    "            _local_df.loc[:, 'fd' if fd else 'random'] = _df.query(\"fd == @fd\").groupby(\"group\")[measure].mean()\n",
    "        dataset_dfs[measure] = _local_df.dropna().copy()\n",
    "    return dataset_dfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6475dc7-b4bd-44ca-99a4-e262c03459c7",
   "metadata": {},
   "source": [
    "## Create the SYN$^e$ plot data\n",
    "\n",
    "First, collect the results of SYN$^e$ and generate the plotting data for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddb1449-f763-493a-b2ff-6b50caa7948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "if not os.path.exists(os.path.join(results_path, f'syn_e_results_0.csv')):\n",
    "    raise ValueError('No SYN results found. Execute `create_syn_e.ipynb` first.')\n",
    "\n",
    "noisy_results = pd.DataFrame()\n",
    "for file in filter(lambda f: f.startswith('syn_e_results_') and f.endswith('.csv'), os.listdir(results_path)):\n",
    "    noisy_results = pd.concat([noisy_results, pd.read_csv(os.path.join(results_path, file))])\n",
    "    \n",
    "for noise_type in (\"copy\", \"bogus\", \"typo\"):\n",
    "    _df = noisy_results.query(\"n_type == @noise_type\").copy()\n",
    "    data_tables = make_SYN_err_data(_df, 'noise', bins=21, min_val=0.0, max_val=0.1)\n",
    "    for measure, df in data_tables.items():\n",
    "        df.to_csv(f'../../paper/figure2_syn_error_{noise_type}_{measure}.dat', sep='\\t', index_label='error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbe2fa1-d745-4618-a922-baf9f561d539",
   "metadata": {},
   "source": [
    "## Create the SYN$^u$ plot data\n",
    "\n",
    "First, collect the results of SYN$^u$ and generate the plotting data for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6cc676-b04c-4270-880d-c031e1befddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "if not os.path.exists(os.path.join(results_path, f'syn_u_results_0.csv')):\n",
    "    raise ValueError('No SYN results found. Execute `create_syn_s.ipynb` first.')\n",
    "\n",
    "keylike_results = pd.DataFrame()\n",
    "for file in filter(lambda f: f.startswith('syn_u_results_') and f.endswith('.csv'), os.listdir(results_path)):\n",
    "    keylike_results = pd.concat([keylike_results, pd.read_csv(os.path.join(results_path, file))])\n",
    "\n",
    "keylike_results.loc[:, \"lhs_relative_uniqueness\"] = (\n",
    "    keylike_results.loc[:, \"lhs_cardinality_inferred\"] / keylike_results.loc[:, \"tuples_inferred\"]\n",
    ")\n",
    "\n",
    "data_tables = make_SYN_err_data(keylike_results, 'lhs_relative_uniqueness', bins=11, min_val=0.0, max_val=1.0)\n",
    "for measure, df in data_tables.items():\n",
    "    df.to_csv(f'../../paper/figure2_syn_keylike_{measure}.dat', sep='\\t', index_label='lhs_uniq')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dae539-5693-4868-98b3-4dd81649d1e9",
   "metadata": {},
   "source": [
    "## Create the SYN$^s$ plot data\n",
    "\n",
    "First, collect the results of SYN$^s$ and generate the plotting data for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538a1570-4968-4454-9f0b-2553a175c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "if not os.path.exists(os.path.join(results_path, f'syn_s_results_0.csv')):\n",
    "    raise ValueError('No SYN results found. Execute `create_syn_s.ipynb` first.')\n",
    "\n",
    "predominant_results = pd.DataFrame()\n",
    "for file in filter(lambda f: f.startswith('syn_s_results_') and f.endswith('.csv'), os.listdir(results_path)):\n",
    "    predominant_results = pd.concat([predominant_results, pd.read_csv(os.path.join(results_path, file))])\n",
    "\n",
    "predominant_results.loc[:, \"rhs_skew\"] = predominant_results.loc[:, [\"rhs_dist_alpha_inferred\", \"rhs_dist_beta_inferred\"]].apply(\n",
    "    lambda row: sd.beta_skewness(row[\"rhs_dist_alpha_inferred\"], row[\"rhs_dist_beta_inferred\"]),\n",
    "    axis=\"columns\",\n",
    ")\n",
    "\n",
    "data_tables = make_SYN_err_data(predominant_results, 'rhs_skew', bins=11, min_val=0.0, max_val=10.0)\n",
    "for measure, df in data_tables.items():\n",
    "    df.to_csv(f'../../paper/figure2_syn_rhsskew_{measure}.dat', sep='\\t', index_label='rhs_skew')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665f6e8b-1668-4950-8e88-f38f4d6204cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
