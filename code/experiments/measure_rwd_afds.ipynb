{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6d90b37-bae0-4ba7-b1c2-86e37ecb4f56",
   "metadata": {
    "tags": []
   },
   "source": [
    "# AFD measurements\n",
    "\n",
    "In this notebook, we apply all AFD measures to the RWD dataset.\n",
    "\n",
    "## Setup\n",
    "First, load all the files from the RWD dataset. Futhermore, set some configuration parameters if running on an HPC cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46adb2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# for Jupyter notebooks: add the path of 'code' to allow importing module\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "from afd_measures import utils as afd_utils\n",
    "\n",
    "data_path = \"../../data/rwd\"\n",
    "gt_path = \"../../data/ground_truth.csv\"\n",
    "results_path = \"../../results\"\n",
    "# batch_i is used to parallelize measuring datasets on the HPC cluster\n",
    "batch_i = int(os.getenv(\"PBS_ARRAYID\", 0))\n",
    "# workers is used to parallelize measuring candidate FDs using joblib\n",
    "workers = int(os.getenv(\"PBS_NUM_PPN\", 1))\n",
    "total_batches = 1 # total number of batches that will be run on the HPC\n",
    "\n",
    "rwd_data = {}\n",
    "for i, file in enumerate(filter(lambda f: f.endswith('.csv'), os.listdir(data_path))):\n",
    "    if i % total_batches != batch_i:\n",
    "        continue\n",
    "    rwd_data[file] = pd.read_csv(os.path.join(data_path, file))\n",
    "    rwd_data[file].columns = [\n",
    "        afd_utils.clean_colname(c) for c in rwd_data[file].columns\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e2f128-8d14-46a8-b72e-680891e3d058",
   "metadata": {},
   "source": [
    "## Calculate measures\n",
    "\n",
    "After setup has been done, calculate the measures. The output dataframe will be written to the results for each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c30705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from typing import Any\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import tqdm\n",
    "\n",
    "from afd_measures import measures as afd_measures\n",
    "\n",
    "measures = [\n",
    "    \"rho\",\n",
    "    \"g2\",\n",
    "    \"g3\",\n",
    "    \"g3_prime\",\n",
    "    \"fraction_of_information\",\n",
    "    \"reliable_fraction_of_information_prime\",\n",
    "    \"smoothed_fraction_of_information\",\n",
    "    \"g1\",\n",
    "    \"g1_prime\",\n",
    "    \"pdep\",\n",
    "    \"tau\",\n",
    "    \"mu_prime\",\n",
    "]\n",
    "\n",
    "\n",
    "def parallelize_measuring(df: pd.DataFrame, table: str, lhs: Any, rhs: Any):\n",
    "    result = {\n",
    "        \"table\": table,\n",
    "        \"lhs\": lhs,\n",
    "        \"rhs\": rhs,\n",
    "    }\n",
    "    _df = df.loc[:, [lhs, rhs]].dropna().copy()\n",
    "    if _df.empty:\n",
    "        result[\"empty\"] = True\n",
    "        return result\n",
    "    result[\"trivial_fd\"] = afd_utils.is_trivial_fd(_df, lhs, rhs)\n",
    "    result[\"exact_fd\"] = afd_utils.is_perfect_fd(_df, lhs, rhs)\n",
    "    for measure in measures:\n",
    "        result[measure] = (\n",
    "            getattr(afd_measures, measure)(_df, lhs, rhs)\n",
    "            if not result[\"trivial_fd\"]\n",
    "            else 1.0\n",
    "        )\n",
    "    return result\n",
    "\n",
    "\n",
    "to_calulate = [\n",
    "    (df, table, lhs, rhs)\n",
    "    for table, df in rwd_data.items()\n",
    "    for lhs, rhs in itertools.permutations(df.columns, 2)\n",
    "]\n",
    "rwd_results = Parallel(n_jobs=workers)(\n",
    "    delayed(parallelize_measuring)(*args) for args in tqdm.tqdm(to_calulate)\n",
    ")\n",
    "# filter out the empty candidate FDs\n",
    "rwd_results_df = pd.DataFrame(rwd_results)\n",
    "if \"empty\" in rwd_results.columns:\n",
    "    rwd_results_df = rwd_results_df.query('empty != True').drop(columns=['empty'])\n",
    "# add the ground truth to the dataframe\n",
    "ground_truth = pd.read_csv(gt_path)\n",
    "ground_truth['afd'] = True\n",
    "rwd_results_df = rwd_results_df.merge(ground_truth, on=['table', 'lhs', 'rhs'])\n",
    "rwd_results_df = rwd_results_df['afd'].fillna(False)\n",
    "rwd_results_df.to_csv(os.path.join(results_path, f'rwd_results_{batch_i}.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
